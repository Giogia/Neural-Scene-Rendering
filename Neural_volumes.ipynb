{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Neural volumes.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm",
   "authorship_tag": "ABX9TyPjOPZCmmKR5+31DUe7/V50",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Giogia/Neural-Volumes/blob/master/Neural_volumes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MEMItnDqJ8-G",
    "colab_type": "code",
    "outputId": "9f74583e-a027-4b7f-9ce3-07d34556a2b5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    }
   },
   "source": [
    "#Init Colab location to repo, mount drive if necessary\n",
    "import os\n",
    "\n",
    "directory = 'gdrive/My Drive/Colab/Neural-Volumes'\n",
    "\n",
    "if os.getcwd() == '/content' and 'gdrive' not in os.listdir():\n",
    "  \n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "\n",
    "if os.getcwd() != '/content/' + directory:\n",
    "  os.chdir(directory)\n",
    "\n",
    "print('\\n', 'Repository Content')\n",
    "%ls"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n",
      "Repository Content \n",
      "\n",
      "\u001B[0m\u001B[01;34mdata\u001B[0m/  \u001B[01;34mexperiments\u001B[0m/        \u001B[01;34mmodels\u001B[0m/               render.py\n",
      "\u001B[01;34meval\u001B[0m/  experiments.tar.gz  Neural_volumes.ipynb  train.py\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "txXEYUYquHH8",
    "colab_type": "code",
    "outputId": "33e1cc0f-fd31-4766-bbeb-6c7340a6ab87",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    }
   },
   "source": [
    "!git pull"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Counting objects: 6, done.\n",
      "Delta compression using up to 4 threads.\n",
      "Compressing objects:  25% (1/4)   \rCompressing objects:  50% (2/4)   \rCompressing objects:  75% (3/4)   \rCompressing objects: 100% (4/4)   \rCompressing objects: 100% (4/4), done.\n",
      "Writing objects:  16% (1/6)   \rWriting objects:  33% (2/6)   \rWriting objects:  50% (3/6)   \rWriting objects:  66% (4/6)   \rWriting objects:  83% (5/6)   \rWriting objects: 100% (6/6)   \rWriting objects: 100% (6/6), 2.02 KiB | 413.00 KiB/s, done.\n",
      "Total 6 (delta 1), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001B[K\n",
      "To https://github.com/Giogia/Neural-Volumes.git\n",
      "   a650d3c..404b405  master -> master\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "23TOba33L4qf",
    "outputId": "a75b8903-0d91-4900-8c2c-959407454b91",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    }
   },
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Wed Apr 22 10:03:38 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wSlkbhSfNCQt",
    "colab_type": "code",
    "outputId": "48cc4fd2-aeac-4aa9-918b-fd62b5018a77",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    }
   },
   "source": [
    "!python train.py experiments/dryice1/experiment2/config.py"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Python 3.6.9 (default, Nov  7 2019, 10:44:02) \n",
      "[GCC 8.3.0]\n",
      "PyTorch 1.4.0\n",
      "train.py experiments/dryice1/experiment2/config.py\n",
      "Output path: experiments/dryice1/experiment2\n",
      "Config loaded (0.01 s)\n",
      "Dataset instantiated (1.40 s)\n",
      "Writer instantiated (0.00 s)\n",
      "Autoencoder instantiated (11.42 s)\n",
      "Optimizer instantiated (0.01 s)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "Iteration 0: loss = 10.87717, kldiv = 0.00706, tvl1 = 0.03984, alphapr = 0.03467, irgbmse = 10.87642, iter/sec = 0.39\n",
      "Iteration 1: loss = 6.76269, kldiv = 0.02326, tvl1 = 0.04227, alphapr = 0.02082, irgbmse = 6.76204\n",
      "Iteration 2: loss = 4.02421, kldiv = 0.05848, tvl1 = 0.05219, alphapr = 0.16705, irgbmse = 4.02196\n",
      "Iteration 3: loss = 3.71406, kldiv = 0.09957, tvl1 = 0.06167, alphapr = 0.41908, irgbmse = 3.70916\n",
      "Iteration 4: loss = 4.61034, kldiv = 0.13133, tvl1 = 0.07447, alphapr = 1.13370, irgbmse = 4.59813\n",
      "Iteration 5: loss = 4.35260, kldiv = 0.15778, tvl1 = 0.08989, alphapr = 0.89720, irgbmse = 4.34257\n",
      "Iteration 6: loss = 4.20940, kldiv = 0.19613, tvl1 = 0.10677, alphapr = 0.56602, irgbmse = 4.20248\n",
      "Iteration 7: loss = 3.67029, kldiv = 0.25510, tvl1 = 0.12982, alphapr = 0.23387, irgbmse = 3.66639\n",
      "Iteration 8: loss = 3.77407, kldiv = 0.32353, tvl1 = 0.15310, alphapr = 0.21277, irgbmse = 3.77009\n",
      "Iteration 9: loss = 4.50409, kldiv = 0.44187, tvl1 = 0.16764, alphapr = 0.28024, irgbmse = 4.49917\n",
      "Iteration 10: loss = 4.62742, kldiv = 0.57339, tvl1 = 0.19723, alphapr = 0.43884, irgbmse = 4.62049, iter/sec = 0.05\n",
      "Iteration 11: loss = 4.36677, kldiv = 0.75667, tvl1 = 0.21787, alphapr = 0.52935, irgbmse = 4.35854\n",
      "Iteration 12: loss = 3.57190, kldiv = 1.06550, tvl1 = 0.24679, alphapr = 0.56312, irgbmse = 3.56274\n",
      "Iteration 13: loss = 3.80310, kldiv = 1.63056, tvl1 = 0.27490, alphapr = 0.56117, irgbmse = 3.79311\n",
      "Iteration 14: loss = 4.21905, kldiv = 2.44620, tvl1 = 0.30615, alphapr = 0.49792, irgbmse = 4.20856\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 133, in <module>\n",
      "    output = ae(iternum, lossweights.keys(), **{k: x.to(\"cuda\") for k, x in data.items()})\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/data_parallel.py\", line 150, in forward\n",
      "    return self.module(*inputs[0], **kwargs[0])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/content/gdrive/My Drive/Colab/Neural-Volumes/models/neurvol1.py\", line 89, in forward\n",
      "    while not done.all():\n",
      "KeyboardInterrupt\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vocCe-hbb1It",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!rm experiments/dryice1/experiment2/log.txt"
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}